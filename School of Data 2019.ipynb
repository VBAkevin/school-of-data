{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Databases, Dashboards, and Death to Paper: Part 1\n",
    "\n",
    "What we're going to accomplish:\n",
    "\n",
    "1. **Extract** data from our asset management system\n",
    "2. **Transform** the data to make it comatible with our open data portal\n",
    "3. **Load** the data into our open data portal\n",
    "\n",
    "...with Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Some Data\n",
    "\n",
    "We're going to download traffic signal data from our asset management system.\n",
    "\n",
    "[Click here](https://atd.knack.com/test#signal-requests/signal-request-details/5bbd028a4c1e902ee11110a3/) to visit a (fake) Traffic Signal Request in our assset management system.\n",
    "\n",
    "![alt text](./img/sig_req.png \"Logo Title Text 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from https://api.knack.com/v1/pages/scene_514/views/view_2571/records?rows_per_page=1000\n",
      "Retrieved 100 records\n",
      "Get field data for object_171\n",
      "Get data from https://api.knack.com/v1/objects/object_171/fields?rows_per_page=1000\n",
      "Retrieved 18 fields\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as print # force pretty printing\n",
    "import knackpy # knack API client\n",
    "\n",
    "\n",
    "auth = {\n",
    "    \"app_id\" : \"5bbcfd7b4ae801302fe650c3\",\n",
    "    \"api_key\" : \"f9debcb0-d0cc-11e8-b6a3-6727e456c7fb\"\n",
    "}\n",
    "\n",
    "# get data\n",
    "kn = knackpy.Knack(\n",
    "    scene=\"scene_514\",\n",
    "    view=\"view_2571\",\n",
    "    ref_obj=[\"object_171\"],\n",
    "    app_id=auth[\"app_id\"],\n",
    "    api_key=auth[\"api_key\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ATD_EVAL_ID': 'TVL19-005420',\n",
      "  'CROSS_ST': ' CUTTING HORSE LN',\n",
      "  'CROSS_ST_BLOCK': 1601,\n",
      "  'EVAL_RANK': 203,\n",
      "  'EVAL_SCORE': '0',\n",
      "  'EVAL_STATUS': 'IN PROGRESS',\n",
      "  'EVAL_TYPE': 'TRAFFIC',\n",
      "  'FUNDING_STATUS': 'None Identified',\n",
      "  'LANDMARK': '',\n",
      "  'LOCATION_LATITUDE': 30.417382,\n",
      "  'LOCATION_LONGITUDE': -97.684626,\n",
      "  'LOCATION_NAME': ' METRIC BLVD / CUTTING HORSE LN',\n",
      "  'PRIMARY_ST': ' METRIC BLVD',\n",
      "  'PRIMARY_ST_BLOCK': 12801,\n",
      "  'RANK_ROUND_MO': 'DEC',\n",
      "  'RANK_ROUND_YR': '2018',\n",
      "  'REQUEST_ID': 'REQ19-003505',\n",
      "  'REQUEST_STATUS': 'RECENTLY RECEIVED',\n",
      "  'id': '5c534c420fd877638727456a'}]\n"
     ]
    }
   ],
   "source": [
    "print(kn.data[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "1. Change column names to lower case\n",
    "\n",
    "2. Drop \"id\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atd_eval_id': 'TVL19-005420',\n",
      " 'cross_st': ' CUTTING HORSE LN',\n",
      " 'cross_st_block': 1601,\n",
      " 'eval_rank': 203,\n",
      " 'eval_score': '0',\n",
      " 'eval_status': 'IN PROGRESS',\n",
      " 'eval_type': 'TRAFFIC',\n",
      " 'funding_status': 'None Identified',\n",
      " 'id': '5c534c420fd877638727456a',\n",
      " 'landmark': '',\n",
      " 'location_latitude': 30.417382,\n",
      " 'location_longitude': -97.684626,\n",
      " 'location_name': ' METRIC BLVD / CUTTING HORSE LN',\n",
      " 'primary_st': ' METRIC BLVD',\n",
      " 'primary_st_block': 12801,\n",
      " 'rank_round_mo': 'DEC',\n",
      " 'rank_round_yr': '2018',\n",
      " 'request_id': 'REQ19-003505',\n",
      " 'request_status': 'RECENTLY RECEIVED'}\n"
     ]
    }
   ],
   "source": [
    "data_lower_case = [{key.lower(): value for key, value in record.items()} for record in kn.data]\n",
    "\n",
    "print(data_lower_case[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atd_eval_id': 'TVL19-005420',\n",
      " 'cross_st': ' CUTTING HORSE LN',\n",
      " 'cross_st_block': 1601,\n",
      " 'eval_rank': 203,\n",
      " 'eval_score': '0',\n",
      " 'eval_status': 'IN PROGRESS',\n",
      " 'eval_type': 'TRAFFIC',\n",
      " 'funding_status': 'None Identified',\n",
      " 'location_latitude': 30.417382,\n",
      " 'location_longitude': -97.684626,\n",
      " 'location_name': ' METRIC BLVD / CUTTING HORSE LN',\n",
      " 'primary_st': ' METRIC BLVD',\n",
      " 'primary_st_block': 12801,\n",
      " 'rank_round_mo': 'DEC',\n",
      " 'rank_round_yr': '2018',\n",
      " 'request_id': 'REQ19-003505',\n",
      " 'request_status': 'RECENTLY RECEIVED'}\n"
     ]
    }
   ],
   "source": [
    "exclude_keys = [\"id\", \"landmark\"]\n",
    "\n",
    "data_filtered = [{key: record.get(key) for key in record.keys() if key not in exclude_keys} for record in data_lower_case]\n",
    "\n",
    "print(data_filtered[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Be patient, this might take a minute...'\n",
      "'100 records updated! Done.'\n"
     ]
    }
   ],
   "source": [
    "from urllib3.exceptions import HTTPError # we need this to handle HTTPError\n",
    "from pypgrest import Postgrest\n",
    "\n",
    "endpoint = \"http://schoolofdata.austintexas.io/signal_requests\"\n",
    "auth_token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoic3VwZXJfdXNlciJ9.4QzadgzRW9KlL72SeA1kM4XjlrD21mSfyEkjm-OUbpc\"\n",
    "\n",
    "# create postgREST client instance\n",
    "pgrest = Postgrest(endpoint, auth_token)\n",
    "\n",
    "print(\"Be patient, this might take a minute...\")\n",
    "\n",
    "try:\n",
    "    pgrest.upsert(data_filtered) # load data\n",
    "    res = pgrest.res.json()\n",
    "    print(\"{} records updated! Done.\".format(len(res)))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(pgrest.res.text)\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
